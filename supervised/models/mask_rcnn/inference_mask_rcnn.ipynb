{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mack RCNN Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T15:42:01.179143Z",
     "iopub.status.busy": "2021-01-23T15:42:01.178063Z",
     "iopub.status.idle": "2021-01-23T15:42:01.196020Z",
     "shell.execute_reply": "2021-01-23T15:42:01.193299Z",
     "shell.execute_reply.started": "2021-01-23T15:42:01.179010Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from object_detection.utils import label_map_util\n",
    "import PIL.Image\n",
    "import io\n",
    "import pathlib\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T14:15:48.336162Z",
     "iopub.status.busy": "2021-01-23T14:15:48.335469Z",
     "iopub.status.idle": "2021-01-23T14:15:48.346801Z",
     "shell.execute_reply": "2021-01-23T14:15:48.344843Z",
     "shell.execute_reply.started": "2021-01-23T14:15:48.336084Z"
    }
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap('labelmap.pbtxt')\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T14:21:36.495289Z",
     "iopub.status.busy": "2021-01-23T14:21:36.494617Z",
     "iopub.status.idle": "2021-01-23T14:23:18.644644Z",
     "shell.execute_reply": "2021-01-23T14:23:18.642058Z",
     "shell.execute_reply.started": "2021-01-23T14:21:36.495211Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(r'mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T18:52:37.894799Z",
     "iopub.status.busy": "2021-01-23T18:52:37.894092Z",
     "iopub.status.idle": "2021-01-23T18:52:37.905494Z",
     "shell.execute_reply": "2021-01-23T18:52:37.903065Z",
     "shell.execute_reply.started": "2021-01-23T18:52:37.894717Z"
    }
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_categories_from_labelmap(r'labelmap.pbtxt', use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T18:52:38.627770Z",
     "iopub.status.busy": "2021-01-23T18:52:38.627098Z",
     "iopub.status.idle": "2021-01-23T18:52:38.640204Z",
     "shell.execute_reply": "2021-01-23T18:52:38.637730Z",
     "shell.execute_reply.started": "2021-01-23T18:52:38.627691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'Cat'}, {'id': 2, 'name': 'Dog'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T14:24:20.114616Z",
     "iopub.status.busy": "2021-01-23T14:24:20.113964Z",
     "iopub.status.idle": "2021-01-23T14:24:20.131213Z",
     "shell.execute_reply": "2021-01-23T14:24:20.128248Z",
     "shell.execute_reply.started": "2021-01-23T14:24:20.114538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'refined_box_encodings': tf.float32,\n",
       " 'proposal_boxes_normalized': tf.float32,\n",
       " 'raw_detection_boxes': tf.float32,\n",
       " 'num_detections': tf.float32,\n",
       " 'detection_anchor_indices': tf.float32,\n",
       " 'detection_multiclass_scores': tf.float32,\n",
       " 'anchors': tf.float32,\n",
       " 'detection_masks': tf.float32,\n",
       " 'num_proposals': tf.float32,\n",
       " 'rpn_features_to_crop': tf.float32,\n",
       " 'detection_scores': tf.float32,\n",
       " 'rpn_objectness_predictions_with_background': tf.float32,\n",
       " 'rpn_box_predictor_features': tf.float32,\n",
       " 'class_predictions_with_background': tf.float32,\n",
       " 'rpn_box_encodings': tf.float32,\n",
       " 'detection_classes': tf.float32,\n",
       " 'proposal_boxes': tf.float32,\n",
       " 'image_shape': tf.float32,\n",
       " 'box_classifier_features': tf.float32,\n",
       " 'mask_predictions': tf.float32,\n",
       " 'detection_boxes': tf.float32,\n",
       " 'raw_detection_scores': tf.float32,\n",
       " 'final_anchors': tf.float32}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.signatures['serving_default'].output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T18:54:45.474546Z",
     "iopub.status.busy": "2021-01-23T18:54:45.473838Z",
     "iopub.status.idle": "2021-01-23T18:54:45.494628Z",
     "shell.execute_reply": "2021-01-23T18:54:45.492437Z",
     "shell.execute_reply.started": "2021-01-23T18:54:45.474464Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "    image = np.asarray(image)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    # Run inference\n",
    "    model_fn = model.signatures['serving_default']\n",
    "    output_dict = model_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    #print(num_detections)\n",
    "    print(output_dict.keys())\n",
    "    for key, value in output_dict.items():\n",
    "        #print(key, value.numpy().shape, type(value))\n",
    "        if len(value.shape) > 1:\n",
    "            output_dict[key] = value[0][:num_detections]\n",
    "        else:\n",
    "            output_dict[key] = value[0]\n",
    "    #output_dict = {key:value[0, :num_detections].numpy() \n",
    "    #               for key,value in output_dict.items()}\n",
    "    #output_dict['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].numpy().astype(np.int64)\n",
    "\n",
    "    # Handle models with masks:\n",
    "    if 'detection_masks' in output_dict:\n",
    "    # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            output_dict['detection_masks'], \n",
    "            output_dict['detection_boxes'],\n",
    "            image.shape[0], image.shape[1])      \n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T18:54:45.945883Z",
     "iopub.status.busy": "2021-01-23T18:54:45.945179Z",
     "iopub.status.idle": "2021-01-23T18:54:45.961302Z",
     "shell.execute_reply": "2021-01-23T18:54:45.958301Z",
     "shell.execute_reply.started": "2021-01-23T18:54:45.945805Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_inference(model, image_path):\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    # Visualization of the results of a detection.\n",
    "    #print(output_dict)\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'].numpy(),\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'].numpy(),\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "\n",
    "    display(Image.fromarray(image_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T15:42:07.833583Z",
     "iopub.status.busy": "2021-01-23T15:42:07.832527Z",
     "iopub.status.idle": "2021-01-23T15:42:08.115088Z",
     "shell.execute_reply": "2021-01-23T15:42:08.112368Z",
     "shell.execute_reply.started": "2021-01-23T15:42:07.833461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7390"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('dataset/downloads/extracted/TAR_GZ.robots.ox.ac.uk_vgg_pets_imageswMR1o1DWRq_DHWToagdXedb7P88RHpceK3WqG77VVwU.tar.gz/images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "len(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T18:54:49.270913Z",
     "iopub.status.busy": "2021-01-23T18:54:49.270282Z",
     "iopub.status.idle": "2021-01-23T18:54:49.592993Z",
     "shell.execute_reply": "2021-01-23T18:54:49.589101Z",
     "shell.execute_reply.started": "2021-01-23T18:54:49.270837Z"
    }
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node StatefulPartitionedCall/functional_1/conv2d/Conv2D}}]]\n\t [[StatefulPartitionedCall/BatchMultiClassNonMaxSuppression_1/MultiClassNonMaxSuppression/Reshape_7/_532]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node StatefulPartitionedCall/functional_1/conv2d/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_43776]\n\nFunction call stack:\nsignature_wrapper -> signature_wrapper\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-57315c43edd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTEST_IMAGE_PATHS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mshow_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fc26e35096af>\u001b[0m in \u001b[0;36mshow_inference\u001b[0;34m(model, image_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Actual detection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference_for_single_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Visualization of the results of a detection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(output_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-987f8a0d7989>\u001b[0m in \u001b[0;36mrun_inference_for_single_image\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serving_default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# All outputs are batches tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_bin/apps/miniconda3/envs/tf-gpu-2.3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m     \"\"\"\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_bin/apps/miniconda3/envs/tf-gpu-2.3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1685\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_flat_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_with_flat_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_bin/apps/miniconda3/envs/tf-gpu-2.3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1734\u001b[0m                         \"got {} ({})\".format(self._flat_signature_summary(), i,\n\u001b[1;32m   1735\u001b[0m                                              type(arg).__name__, str(arg)))\n\u001b[0;32m-> 1736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_with_structured_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_bin/apps/miniconda3/envs/tf-gpu-2.3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# cross-replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_unused_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\n\u001b[0m\u001b[1;32m    116\u001b[0m                                                     cancellation_manager)\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_bin/apps/miniconda3/envs/tf-gpu-2.3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/my_bin/apps/miniconda3/envs/tf-gpu-2.3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_bin/apps/miniconda3/envs/tf-gpu-2.3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node StatefulPartitionedCall/functional_1/conv2d/Conv2D}}]]\n\t [[StatefulPartitionedCall/BatchMultiClassNonMaxSuppression_1/MultiClassNonMaxSuppression/Reshape_7/_532]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node StatefulPartitionedCall/functional_1/conv2d/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_43776]\n\nFunction call stack:\nsignature_wrapper -> signature_wrapper\n"
     ]
    }
   ],
   "source": [
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    show_inference(model, image_path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2.3",
   "language": "python",
   "name": "tf-gpu-2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
